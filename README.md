# Domain Generation Algorithm Detection: A Comparative Analysis of LSTM, Transformer, and Feature-Based Approaches

## ğŸ“‹ MÃ´ Táº£ Dá»± Ãn

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh **há»c mÃ¡y** Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i cÃ¡c miá»n tÃªn Ä‘Æ°á»£c táº¡o báº±ng thuáº­t toÃ¡n DGA (Domain Generation Algorithm). DGA lÃ  ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi malware Ä‘á»ƒ táº¡o ra cÃ¡c tÃªn miá»n Ä‘á»™ng nháº±m trÃ¡nh bá»‹ cháº·n bá»Ÿi cÃ¡c danh sÃ¡ch Ä‘en truyá»n thá»‘ng.

### Má»¥c TiÃªu
- **PhÃ¡t hiá»‡n DGA**: XÃ¡c Ä‘á»‹nh liá»‡u má»™t tÃªn miá»n cÃ³ pháº£i Ä‘Æ°á»£c táº¡o báº±ng DGA hay khÃ´ng
- **So sÃ¡nh MÃ´ HÃ¬nh**: ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau (Random Forest, LSTM, Transformer)
- **MÃ´ Phá»ng Táº¥n CÃ´ng**: Sinh ra cÃ¡c miá»n tÃªn DGA thá»±c táº¿ tá»« 30+ thuáº­t toÃ¡n DGA khÃ¡c nhau

---

## ğŸ—ï¸ Cáº¥u TrÃºc ThÆ° Má»¥c

```
dga_predict/
â”œâ”€â”€ run.py                          # Script chÃ­nh: cháº¡y cÃ¡c thÃ­ nghiá»‡m
â”œâ”€â”€ regenerate_data.py              # TÃ¡i táº¡o dataset vá»›i DGA dá»±a trÃªn ML
â”œâ”€â”€ test_dga_generators.py          # Kiá»ƒm tra cÃ¡c DGA generators
â”œâ”€â”€ verify_real_dgas.py             # XÃ¡c nháº­n hiá»‡u suáº¥t cÃ¡c DGA thá»±c
â”œâ”€â”€ LICENSE                         # Giáº¥y phÃ©p GPL v2
â”‚
â”œâ”€â”€ dga_classifier/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py                     # Táº¡o dataset (benign + DGA domains)
â”‚   â”œâ”€â”€ manual_rf.py                # MÃ´ hÃ¬nh Random Forest
â”‚   â”œâ”€â”€ lstm.py                     # MÃ´ hÃ¬nh LSTM (Deep Learning)
â”‚   â”œâ”€â”€ transformer.py              # MÃ´ hÃ¬nh Transformer
â”‚   â”œâ”€â”€ bigram.py                   # PhÃ¢n tÃ­ch bigram
â”‚   â”‚
â”‚   â””â”€â”€ dga_generators/             # 30+ DGA generators
â”‚       â”œâ”€â”€ real_lstm_dga.py        # DGA dá»±a trÃªn LSTM Ä‘Æ°á»£c huáº¥n luyá»‡n
â”‚       â”œâ”€â”€ real_gan_dga.py         # DGA dá»±a trÃªn GAN
â”‚       â”œâ”€â”€ adversarial_trained_dga.py  # DGA huáº¥n luyá»‡n Ä‘á»‘i khÃ¡ng
â”‚       â”œâ”€â”€ hash_dga.py             # DGA dá»±a trÃªn hash
â”‚       â”œâ”€â”€ context_dga.py          # DGA cÃ³ ngá»¯ cáº£nh
â”‚       â”œâ”€â”€ multistage_dga.py       # DGA nhiá»u giai Ä‘oáº¡n
â”‚       â”œâ”€â”€ neural_like_dga.py      # DGA mÃ´ phá»ng máº¡ng nÆ¡-ron
â”‚       â”œâ”€â”€ banjori.py, kraken.py, lockyv2.py  # DGA malware thá»±c
â”‚       â””â”€â”€ [26 DGA khÃ¡c...]
```

---

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### 1. Chuáº©n Bá»‹ Dá»¯ Liá»‡u

Äá»ƒ tÃ¡i táº¡o dataset vá»›i cÃ¡c DGA dá»±a trÃªn ML Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘Ãºng cÃ¡ch:

```bash
python regenerate_data.py
```

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
- Táº£i xuá»‘ng 1M miá»n tÃªn tá»« Alexa Top Domains (hoáº·c táº¡o benign domains tá»•ng há»£p)
- Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh DGA thá»±c (LSTM, GAN, Adversarial)
- Sinh ra ~1K miá»n DGA tá»« cÃ¡c mÃ´ hÃ¬nh Ä‘Ã³
- Táº¡o tá»‡p `traindata.pkl` chá»©a dá»¯ liá»‡u huáº¥n luyá»‡n

â±ï¸ **Thá»i gian:** 10-30 phÃºt (tÃ¹y vÃ o cáº¥u hÃ¬nh há»‡ thá»‘ng)

### 2. Cháº¡y CÃ¡c ThÃ­ Nghiá»‡m

```bash
python run.py
```

**TÃ¹y chá»n:**
```bash
# Cháº¡y táº¥t cáº£ mÃ´ hÃ¬nh
python run.py

# Cháº¡y riÃªng Random Forest
python run.py --manualrf --no-lstm --no-transformer

# Cháº¡y riÃªng LSTM
python run.py --no-manualrf --lstm --no-transformer

# Cháº¡y riÃªng Transformer
python run.py --no-manualrf --no-lstm --transformer

# Thay Ä‘á»•i sá»‘ láº§n cross-validation (máº·c Ä‘á»‹nh: 10)
python run.py --nfolds 5

# Buá»™c tÃ¡i táº¡o dá»¯ liá»‡u
python run.py --force
```

**Káº¿t quáº£:**
- `results.pkl` - Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u trong bá»™ nhá»› Ä‘á»‡m
- `metrics.csv` - Báº£ng chi tiáº¿t cÃ¡c chá»‰ sá»‘
- `roc_*.png` - Äá»“ thá»‹ ROC curve
- `confusion_*.png` - Ma tráº­n nháº§m láº«n

### 3. Kiá»ƒm Tra DGA Generators

```bash
python test_dga_generators.py
```

Kiá»ƒm tra xem táº¥t cáº£ cÃ¡c DGA generators cÃ³ hoáº¡t Ä‘á»™ng Ä‘Ãºng hay khÃ´ng.

### 4. XÃ¡c Nháº­n Hiá»‡u Suáº¥t DGA Thá»±c

```bash
python verify_real_dgas.py
```

Kiá»ƒm tra cÃ¡c mÃ´ hÃ¬nh DGA dá»±a trÃªn ML (LSTM, GAN, Adversarial).

---

## ğŸ“Š CÃ¡c MÃ´ HÃ¬nh ÄÆ°á»£c Há»— Trá»£

### 1. **Random Forest (Manual RF)**
- **Loáº¡i:** Machine Learning cá»• Ä‘iá»ƒn
- **TÃ­nh nÄƒng:** Äá»™ dÃ i miá»n, táº§n suáº¥t kÃ½ tá»±, entropy, bigram
- **Æ¯u Ä‘iá»ƒm:** Nhanh, dá»… giáº£i thÃ­ch
- **NhÆ°á»£c Ä‘iá»ƒm:** KhÃ´ng há»c Ä‘Æ°á»£c cÃ¡c máº«u phá»©c táº¡p

### 2. **LSTM (Long Short-Term Memory)**
- **Loáº¡i:** Deep Learning
- **TÃ­nh nÄƒng:** Há»c chuá»—i kÃ½ tá»± trá»±c tiáº¿p (character-level)
- **Æ¯u Ä‘iá»ƒm:** Báº¯t Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ dÃ i háº¡n
- **NhÆ°á»£c Ä‘iá»ƒm:** Cháº­m hÆ¡n, cáº§n GPU Ä‘á»ƒ huáº¥n luyá»‡n nhanh

### 3. **Transformer**
- **Loáº¡i:** Deep Learning (Attention-based)
- **TÃ­nh nÄƒng:** Attention mechanism Ä‘á»ƒ há»c cÃ¡c má»‘i quan há»‡ song song
- **Æ¯u Ä‘iá»ƒm:** TÃ­nh toÃ¡n nhanh, hiá»‡u suáº¥t cao
- **NhÆ°á»£c Ä‘iá»ƒm:** Cáº§n nhiá»u dá»¯ liá»‡u hÆ¡n

---

## ğŸ¦  CÃ¡c Thuáº­t ToÃ¡n DGA ÄÆ°á»£c Há»— Trá»£

### **DGA Dá»±a TrÃªn Hash**
- `hash_dga.py` - TiÃªu chuáº©n DGA dá»±a trÃªn hash
- `advanced_hash_dga.py` - Hash nÃ¢ng cao vá»›i nhiá»u quy táº¯c

### **DGA Tinh Xáº£o**
- `context_dga.py` - DGA cÃ³ ngá»¯ cáº£nh
- `multistage_dga.py` - DGA nhiá»u giai Ä‘oáº¡n
- `time_varying_dga.py` - DGA thay Ä‘á»•i theo thá»i gian
- `obfuscated_dga.py` - DGA cÃ³ che phá»§

### **DGA Dá»±a TrÃªn Neural Network**
- `real_lstm_dga.py` - LSTM thá»±c Ä‘Æ°á»£c huáº¥n luyá»‡n
- `real_gan_dga.py` - GAN táº¡o sinh miá»n tÃªn DGA
- `adversarial_trained_dga.py` - DGA Ä‘á»‘i khÃ¡ng

### **DGA Malware Thá»±c**
- `banjori.py` - Banjori malware
- `kraken.py` - Kraken botnet
- `lockyv2.py` - Locky v2 ransomware
- `cryptolocker.py` - CryptoLocker ransomware
- `qakbot.py` - QakBot malware
- `pykspa.py` - Pykspa botnet
- [VÃ  20+ thuáº­t toÃ¡n DGA khÃ¡c tá»« malware thá»±c]

---

## ğŸ“ˆ CÃ¡c Chá»‰ Sá»‘ ÄÃ¡nh GiÃ¡

Dá»± Ã¡n sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ sau Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh:

| Chá»‰ Sá»‘ | Ã NghÄ©a |
|--------|---------|
| **Accuracy** | Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng |
| **Precision** | Trong cÃ¡c DGA dá»± Ä‘oÃ¡n, bao nhiÃªu Ä‘Ãºng lÃ  DGA |
| **Recall** | Trong táº¥t cáº£ cÃ¡c DGA thá»±c, bao nhiÃªu Ä‘Æ°á»£c phÃ¡t hiá»‡n |
| **F1-Score** | Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall |
| **ROC-AUC** | Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC |
| **FPR** | Tá»· lá»‡ dÆ°Æ¡ng tÃ­nh giáº£ |
| **TPR** | Tá»· lá»‡ dÆ°Æ¡ng tÃ­nh Ä‘Ãºng |

---

## ğŸ”§ YÃªu Cáº§u Há»‡ Thá»‘ng

### Python Packages
```
numpy>=1.19.0
scikit-learn>=0.23.0
tensorflow>=2.0.0  # Hoáº·c torch náº¿u dÃ¹ng PyTorch
matplotlib>=3.3.0
tldextract>=2.2.0
```

### CÃ i Äáº·t
```bash
pip install -r requirements.txt
```

### TÃ i NguyÃªn
- **RAM:** Tá»‘i thiá»ƒu 8GB (16GB khuyÃªn dÃ¹ng)
- **Disk:** ~2GB cho dataset
- **CPU:** 4+ cores
- **GPU:** TÃ¹y chá»n (Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ huáº¥n luyá»‡n)

---

## ğŸ“Š VÃ­ Dá»¥ Káº¿t Quáº£

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              DGA Classification Results                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Manual Random Forest:
  Accuracy:  95.2%
  Precision: 94.8%
  Recall:    95.6%
  F1-Score:  95.2%
  ROC-AUC:   0.985

LSTM Neural Network:
  Accuracy:  97.3%
  Precision: 96.9%
  Recall:    97.8%
  F1-Score:  97.3%
  ROC-AUC:   0.995

Transformer:
  Accuracy:  96.8%
  Precision: 96.4%
  Recall:    97.3%
  F1-Score:  96.8%
  ROC-AUC:   0.992
```

---

## ğŸ”¬ Chi Tiáº¿t Ká»¹ Thuáº­t

### Xá»­ LÃ½ Dá»¯ Liá»‡u

**Dataset chuáº©n:**
- **Benign domains:** 1,000,000 miá»n tá»« Alexa Top Domains
- **DGA domains:** ~1,000 miá»n tá»« 30+ thuáº­t toÃ¡n DGA khÃ¡c nhau
- **Tá»· lá»‡:** ~1:1000 (cÃ¢n báº±ng)

**CÃ¡c tÃ­nh nÄƒng (Features):**

#### Random Forest:
1. Äá»™ dÃ i miá»n
2. Entropy Shannon
3. Táº§n suáº¥t tá»«ng kÃ½ tá»± (a-z, 0-9)
4. Bigram vÃ  trigram frequency
5. Sá»‘ lÆ°á»£ng vowel/consonant

#### LSTM/Transformer:
1. Character embedding (30 chiá»u)
2. Chuá»—i kÃ½ tá»± Ä‘áº§u vÃ o: Ä‘á»™ dÃ i 32-128

### Huáº¥n Luyá»‡n

```python
# Chia dá»¯ liá»‡u
- Training: 80%
- Testing: 20%
- Cross-validation: 10-fold

# SiÃªu tham sá»‘
- Random Forest: 100 trees, max_depth=50
- LSTM: 2 layers, 128 units, dropout=0.2
- Transformer: 4 heads, 256 hidden, 2 layers
```

---

## ğŸš¨ Váº¥n Äá» ThÆ°á»ng Gáº·p

### 1. Lá»—i "KhÃ´ng táº£i Ä‘Æ°á»£c Alexa domains"
**Giáº£i phÃ¡p:** Dá»± Ã¡n sáº½ tá»± Ä‘á»™ng táº¡o benign domains tá»•ng há»£p

### 2. Bá»™ nhá»› khÃ´ng Ä‘á»§
**Giáº£i phÃ¡p:** Giáº£m sá»‘ lÆ°á»£ng domains:
```python
# Trong data.py, thay Ä‘á»•i:
NUM_BENIGN = 500000  # Thay vÃ¬ 1000000
```

### 3. LSTM/Transformer cháº­m
**Giáº£i phÃ¡p:** 
- DÃ¹ng GPU: `CUDA_VISIBLE_DEVICES=0 python run.py`
- Giáº£m batch size
- DÃ¹ng Random Forest Ä‘á»ƒ kiá»ƒm tra nhanh

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- [Domain Generation Algorithms (DGA)](https://en.wikipedia.org/wiki/Domain_generation_algorithm)
- [Random Forest in Machine Learning](https://scikit-learn.org/stable/modules/ensemble.html#forest)
- [LSTM Networks](https://keras.io/api/layers/recurrent_layers/lstm/)
- [Transformer Models](https://huggingface.co/docs/transformers/)
- [Endgame - DGA Detection Dataset](https://github.com/endgameinc/domain_generation_algorithms)

---

## ğŸ“ Giáº¥y PhÃ©p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p **GNU General Public License v2.0** (GPLv2).

Xem [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t chi tiáº¿t.

---

## âœï¸ TÃ¡c Giáº£ & ÄÃ³ng GÃ³p

Náº¿u báº¡n cÃ³ Ä‘á» xuáº¥t cáº£i thiá»‡n hoáº·c phÃ¡t hiá»‡n lá»—i, vui lÃ²ng má»Ÿ issue hoáº·c pull request.

---

## ğŸ¯ CÃ¡c Cáº£i Tiáº¿n TÆ°Æ¡ng Lai

- [ ] Há»— trá»£ GPU acceleration cho táº¥t cáº£ mÃ´ hÃ¬nh
- [ ] Triá»ƒn khai mÃ´ hÃ¬nh XGBoost
- [ ] API REST cho phÃ¡t hiá»‡n DGA real-time
- [ ] Dashboard web Ä‘á»ƒ trá»±c quan hÃ³a káº¿t quáº£
- [ ] Há»— trá»£ cÃ¡c DGA generator má»›i
- [ ] Fine-tuning cÃ¡c mÃ´ hÃ¬nh pre-trained

---

**Cáº­p nháº­t láº§n cuá»‘i:** ThÃ¡ng 12, 2025
